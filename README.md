# web_crawler
A web crawler that crawls websites with a given link depth (8) and a maximum limit of 10,000 pages visited. 
The web crawler starts from a predefined URL (seed) and follows the found links to dive deeper. 
The main purpose of this crawler is to detect the presence of some terms on the page and collect statistics. 
To start the application, you can use the web_crawler.bat file (this file contains the path to the configuration file without which the application will not work). 
Also in the same directory with .bat and .jar files for successful launch must be located in the folder "logs".
